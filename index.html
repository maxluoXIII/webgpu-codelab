<!DOCTYPE html>

<html>

<head>
    <meta charset="utf-8">
    <title>WebGPU Life</title>
</head>

<body>
    <canvas width="512" height="512"></canvas>
    <script type="module">
        const canvas = document.querySelector("canvas");

        // WebGPU code goes here
        if (!navigator.gpu) {
            throw new Error("WebGPU not supported on this browser.");
        }
        const adapter = await navigator.gpu.requestAdapter();
        if (!adapter) {
            throw new Error("No appropriate GPUAdapter found.");
        }
        const device = await adapter.requestDevice();

        const context = canvas.getContext("webgpu");
        const canvasFormat = navigator.gpu.getPreferredCanvasFormat();
        context.configure({
            device: device,
            format: canvasFormat,
        });

        const vertices = new Float32Array([
            // X,    Y,
            -0.8, -0.8, // Triangle 1
             0.8, -0.8,
             0.8,  0.8,

            -0.8,  0.8, // Triangle 2
             0.8,  0.8,
            -0.8, -0.8,
        ]);
        const vertexBuffer = device.createBuffer({
            label: "Cell vertices",
            size: vertices.byteLength,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
        });
        device.queue.writeBuffer(vertexBuffer, /*bufferOffset=*/0, vertices);
        const vertexBufferLayout = {
            arrayStride: 8,
            attributes: [{
                format: "float32x2",
                offset: 0,
                shaderLocation: 0, // Position, see vertex shader
            }],
        };

        const cellShaderModule = device.createShaderModule({
            label: "Cell shader",
            code: `
                // Shader code (WGSL)

                // Vertex shader: convert vertex to position in clip space
                // @location references shaderLocation
                @vertex
                fn vertexMain(@location(0) pos: vec2f) -> @builtin(position) vec4f {
                    return vec4f(pos, 0, 1); // (X, Y, Z, W)
                }

                // Fragment shader: return color of pixel in rasterized triangle
                // @location references colorAttachment index in beginRenderPass
                @fragment
                fn fragmentMain() -> @location(0) vec4f {
                    return vec4f(1, 0, 0, 1); // (Red, Green, Blue, Alpha)
                }
            `
        });

        const cellPipeline = device.createRenderPipeline({
            label: "Cell pipeline",
            layout: "auto", // Pipeline builds input layout from shaders
            vertex: {
                module: cellShaderModule,
                entryPoint: "vertexMain",
                buffers: [vertexBufferLayout]
            },
            fragment: {
                module: cellShaderModule,
                entryPoint: "fragmentMain",
                targets: [{
                    format: canvasFormat
                }]
            }
        });

        // Record commands for GPU (does not execute here)
        const encoder = device.createCommandEncoder();
        const pass = encoder.beginRenderPass({
            colorAttachments: [{
                view: context.getCurrentTexture().createView(),
                loadOp: "clear",
                clearValue: { r: 0, g: 0, b: 0.4, a: 1 },
                storeOp: "store",
            }]
        });
        pass.setPipeline(cellPipeline);
        pass.setVertexBuffer(0, vertexBuffer); // 0 is index for which vertex buffer to set (pipeline vertex.buffers)
        pass.draw(vertices.length / 2); // # vertices: 6 vertices
        pass.end();

        // Execute the commands
        // Finish the command buffer and immediately submit it
        device.queue.submit([encoder.finish()]);
    </script>
</body>

</html>